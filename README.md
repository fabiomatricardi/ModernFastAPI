<img src="https://github.com/fabiomatricardi/ModernFastAPI/raw/main/NtworkGPTbanner.jpg" height=150><img src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*pS7o_15V-Zndw8S9ysqixw.png" height=150><img src="https://github.com/fabiomatricardi/ModernFastAPI/raw/main/networkGPT3.png" height=150>



# ModernFastAPI
Repo of the code from the Medium article - Build a powerful LLM API right on your computer

This Project has 3 parts:
1. Create your first FastAPI and interact with it
2. Create a Streamlit AI app where you use TinyLlama-1B-OpenOrca as Instruction AI you can reach in your Local Network
3. **Use llama-cpp-python built in API and Streamlit to give your Team a nice Chatbot**   (coming soon0


### Here the articles on Medium

- [Create your LLM API: your ChatBOT as a service — part 1](https://medium.com/generative-ai/create-your-llm-api-your-chatbot-as-a-service-part-1-4d4213182a1a)
- [Create your LLM API: your ChatBOT as a service — part 2](https://generativeai.pub/create-your-llm-api-your-chatbot-as-a-service-part-2-b21eb6efea72)
- [Create your LLM API: ChatBOT as a service — part 3](https://generativeai.pub/create-your-llm-api-chatbot-as-a-service-part-3-ca336d56f0d3)

### Part 3 file
This is the python file for the textual interface as described in the part 3 article

The result will be as shown below (terminal server llama-cpp-python on the left, chat interface on the right):
<img src="https://github.com/fabiomatricardi/ModernFastAPI/raw/main/fastOpenAI-API1.gif" width=1000>
